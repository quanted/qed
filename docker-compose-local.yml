version: '2.1'
volumes:
  collected_static: {}
services:

  # QED Django front-end
  qed_django:
    restart: unless-stopped
    image: dbsmith88/qed_django  # use qed image w/ tag = VERSION, default = latest
    expose:
      - "8080"
    command: ["/bin/bash", "/src/docker_start_local.sh"]
    volumes:
      - .:/src  # map qed/ to container's /src for updating w/out rebuilding images
#      - /var/www/app_data:/src/app-data
      - ./static_qed:/src/collected_static
    environment:
      - REDIS_HOSTNAME=redis
      #these echo in the environmental variable to the running docker container
      #so that is can be picked up by the django settings 
      - DOCKER_HOSTNAME=docker
      #- DOCKER_SECRET_KEY=${SECRET_KEY}
      - HMS_RELEASE=${HMS_RELASE:-0}
      - IN_PROD=${IN_PROD:-0}
      - IN_DOCKER=True
    links:
      - redis
      - mongodb

  # Redis (message broker)
  redis:
    restart: unless-stopped
    image: redis:latest
    hostname: redis
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - ./redis.config:/usr/local/etc/redis/redis.conf
    expose:
      - "6379"

  # ubertool_cts nodejs submodule
#  cts_nodejs:
#    restart: unless-stopped
#    build: ./cts_nodejs
#    # image: cts-nodejs
#    image: quanted/cts_nodejs
#    expose:
#      - "4000"
#    environment:
#      - NODEJS_HOST=cts_nodejs
#      - NODEJS_PORT=4000
#      - REDIS_HOSTNAME=redis
#      - REDIS_PORT=6379
#    links:
#      - redis
#    # volumes:
#    #   - ./cts_nodejs:/src

  # # Celery worker - manager calc
#  worker_manager:
#    restart: unless-stopped
#    build:
#      context: ./cts_celery
#      dockerfile: Dockerfile
#    # image: cts-celery
#    image: quanted/cts_celery
#    # command: celery worker -A tasks -Q manager_queue -l info -n manager_worker -c 1
#    command: celery -A tasks worker -Q manager_queue -l info -n manager_worker -c 1
#    links:
#      - redis
#    environment:
#      - REDIS_HOSTNAME=redis
#      - DOCKER_HOSTNAME=${HOSTNAME}
#    volumes:
#      - ./cts_celery:/src

  # # Celery worker - cts calc
#  worker_cts:
#    restart: unless-stopped
#    build:
#      context: ./cts_celery
#      dockerfile: Dockerfile
#    # image: cts-celery
#    image: quanted/cts_celery
#    # command: celery worker -A tasks -Q cts_queue -l info -n cts_worker -c 2
#    command: celery -A tasks worker -Q cts_queue -l info -n cts_worker -c 2
#    links:
#      - redis++
#      - qed_django
#    environment:
#      - REDIS_HOSTNAME=redis
#      - DOCKER_HOSTNAME=${HOSTNAME}
#    volumes:
#      - ./cts_celery:/src

  qed_nginx:
    restart: unless-stopped
    # build: ../cts_nginx
    build:
      context: ./qed_nginx
      args:
        config: nginx_basic.conf
    ports:
      - "8080:80"
    links:
      - qed_django:uwsgi_django  # Nginx.conf can reference "qed_django" service with the hostname 'uwsgi' or 'qed_django'
#      - cts_nodejs:cts_nodejs
      - qed_flask:uwsgi_flask
#      - cyan-api:uwsgi_flask
#    volumes:
#      - /var/www/nginx/certs:/etc/nginx/qed # this points to the keys directory
#      - /etc/letsencrypt:/etc/letsencrypt  # certs from letsencrypt (uses certbot)
    volumes_from:
      - qed_django:ro  # Mount all volumes from "qed_django" to NGINX, so it can access the collected static files

  # flask_qed Flask back-end
  qed_flask:
    restart: unless-stopped
    image: dbsmith88/flask_qed:latest  # use qed image w/ tag = VERSION, default = latest
    expose:
      - "7777"
    links:
      - redis
      - mongodb
      - qed_celery
    environment:
      - REDIS_HOSTNAME=redis
      - DOCKER_HOSTNAME=docker
    volumes:
      - ./flask_qed:/src
#      - /var/www/sampreprocessed:/src/pram_flask/ubertool/ubertool/sam/bin/Preprocessed
#      - /var/www/samresults:/src/pram_flask/ubertool/ubertool/sam/bin/Results
#      - /var/www/qed-basins:/src/hms_flask/data/qed-basins
      - collected_static:/src/collected_static
#      - /var/www/app_data/hms:/src/hms-data
    depends_on:
      - mongodb
#    logging:
#      options:
#        max-size: "200k"
#        max-file: "10"

  # mongoDB database container
  mongodb:
    restart: unless-stopped
    image: mongo:latest
    volumes:
      - /var/www/mongodb:/data/db
    expose:
      - "27017"
    ports:
      - "27017:27017"

  # Celery container for async task execution
  qed_celery:
    restart: unless-stopped
    image: dbsmith88/flask_qed:latest
    volumes:
      - ./flask_qed:/src
#      - /var/www/sampreprocessed:/src/pram_flask/ubertool/ubertool/sam/bin/Preprocessed
#      - "../samresults:/src/pram_flask/ubertool/ubertool/sam/bin/Results"
#      - "../qed-basins:/src/hms_flask/data/qed-basins"
#      - collected_static:/src/collected_static
    links:
      - redis
      - mongodb
    command: conda run -n pyenv --no-capture-output celery -A celery_cgi worker -Q qed --loglevel=INFO -n qed_worker --uid=daemon
    environment:
      - REDIS_HOSTNAME=redis
      - DOCKER_HOSTNAME=docker
      - DASK_SCHEDULER=dask_scheduler:8786
#      - C_FORCE_ROOT=TRUE
#    logging:
#      options:
#        max-size: "200k"
#        max-file: "10"

  hms_dotnetcore:
    restart: unless-stopped
#    image: qed_hms_dotnetcore
    image: dbsmith88/hms_dotnetcore
#    build:
#      context: ./windows/hms
#      dockerfile: ./Web.Services/Dockerfile
    environment:
      - MONGODB=mongodb
      - FLASK_SERVER=http://qed_nginx:7777
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    expose:
     - "80"
    volumes:
      - "./windows/hms/Web.Services/App_Data:/app/App_Data"

  # Dask Containers
  dask_scheduler:
    restart: unless-stopped
    image: dbsmith88/qed-dask:dev-np
#    image: qed-dask-local
    hostname: dask-scheduler
    expose:
     - 8786
     - 8787
    command: ["conda", "run", "-n", "pyenv", "--no-capture-output", "dask-scheduler"]

  dask_worker:
    restart: unless-stopped
    image: dbsmith88/qed-dask:dev-np
#    image: qed-dask-local
    hostname: dask-worker
#    command: ["conda", "run", "-n", "pyenv", "--no-capture-output", "dask-worker", "dask-scheduler:8786", "--nprocs", "1", "--nthreads","2"]
    environment:
      PYTHONPATH: '/src:/src/qed:/src/qed/flask_qed'
      IN_DOCKER: "True"
      HMS_BACKEND_SERVER_INTERNAL: "http://hms_dotnetcore:80/"
      HMS_WORKFLOW_BACKEND: "https://ceamdev.ceeopdev.net/hms/rest/"
    volumes:
       - ".:/src/qed"

  # Apache Tomcat container
#  qed-tomcat:
#    restart: unless-stopped
#    build:
#      # context: ./qed_tomcat
#      context: .
#      dockerfile: Dockerfile_Tomcat
#    # image: cts_tomcat:${VERSION:-latest}
#    image: quanted/qed-tomcat
#    expose:
#      - "8080"
#    environment:
#      - JAVA_OPTS=-Xmx1g
#    volumes:
#      - ./secrets/tomcat/tomcat-users.xml:/usr/local/tomcat/conf/tomcat-users.xml
#      - ./secrets/tomcat/webapps:/usr/local/tomcat/webapps
#      - ./secrets/tomcat/chemaxon/licenses:/home/tomcat/.chemaxon/licenses

#  pisces-db:
#    restart: unless-stopped
#    image: mdillon/postgis
#    expose:
#      - "5432"
#    volumes:
#      - /var/www/pisces:/docker-entrypoint-initdb.d

  # Cyanweb Flask API
#  cyan-api:
#    restart: unless-stopped
#    build:
#      context: ./EPA-Cyano-Web
#      dockerfile: docker/flask/Dockerfile
#    expose:
#      - "5001"
#    depends_on:
#      - cyan-db
#    volumes:
#      - ./EPA-Cyano-Web/config:/config
#    environment:
#      # Does environment overwrite env_file, or vice versa?
#      - DOCKER_HOSTNAME=${HOSTNAME}
#    links:
#      - cyan-db
#    env_file:
#      # Would set_enviornment.py overwrite env vars in default below (hope so).
#      - ${CYAN_CONFIG:-./EPA-Cyano-Web/config/environments/local_docker_dev.env}

  # Cyanweb Celery Worker
#  cyan-celery:
#    restart: unless-stopped
#    build:
#      context: ./EPA-Cyano-Web
#      dockerfile: docker/flask/Dockerfile
#    image: cyan-celery
#    container_name: cyan-celery
#    command: celery -A celery_worker.celery worker --loglevel=INFO -c 1
#    depends_on:
#      - cyan-db
#      - redis
#    volumes:
#      - ./EPA-Cyano-Web/config:/config
#      - ./EPA-Cyano-Web/cyan_flask/:/cyan_flask
#    environment:
#      - DOCKER_HOSTNAME=${HOSTNAME}
#    env_file:
#      - ${CYAN_CONFIG:-./EPA-Cyano-Web/config/environments/local_docker_dev.env}

  # Cyanweb MySQL DB
#  cyan-db:
#    restart: unless-stopped
#    build:
#      context: ./EPA-Cyano-Web
#      dockerfile: docker/mysql/Dockerfile
#    volumes:
#      # NOTE: Optional volume for existing DB dump, defaults to blank dummy file if no dump
#      - ${SQL_DUMP:-./EPA-Cyano-Web/cyan_mysql/no_dump.txt}:/tmp/dump.sql  # use optional dump file to build container DB
#      - /var/www/app_data/cyano:/var/lib/mysql
#    environment:
#      - MYSQL_RANDOM_ROOT_PASSWORD=yes
#    env_file:
#      - ${CYAN_CONFIG:-./EPA-Cyano-Web/config/environments/local_docker_dev.env}
